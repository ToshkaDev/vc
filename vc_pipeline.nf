#!/usr/bin/env nextflow

/*
 * Pipeline parameters
 */

// file of input files, one per line
params.input_csv = "${projectDir}/data/paired-end.csv"
// folder with the genome index generated by STAR
params.genome_index="${projectDir}/data/genome/genome_index"

params.genome="${projectDir}/data/genome/genome.fa"
params.genome_fai="${projectDir}/data/genome/genome.fa.fai"
params.genome_dict="${projectDir}/data/genome/genome.dict"

include { FASTP } from './modules/fastp/main.nf'
include { STAR } from './modules/star/main.nf'
include { GATK_ADD_REPLACE_READ_GROUPS } from './modules/gatk/readgroups/main.nf'
include { GATK_MARK_DUPLICATES } from './modules/gatk/markduplicates/main.nf'
include { GATK_SPLIT_NCIGAR_READS } from './modules/gatk/splitncigar/main.nf'

workflow {

    read_ch = Channel.fromPath(params.input_csv)
        .splitCsv(header:true)
        .map { row -> [row.sample_id, file(row.fastq_1), file(row.fastq_2)] }

    FASTP(read_ch)

    STAR(FASTP.out.trimmed_reads, params.genome_index)

    GATK_ADD_REPLACE_READ_GROUPS(STAR.out.bam)

    GATK_MARK_DUPLICATES(GATK_ADD_REPLACE_READ_GROUPS.out.rgs)

    GATK_SPLIT_NCIGAR_READS(GATK_MARK_DUPLICATES.out.dups, params.genome, params.genome_fai, params.genome_dict)
}
